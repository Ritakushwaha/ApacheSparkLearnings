{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2c04de3",
   "metadata": {},
   "source": [
    "# Writing Windows Function\n",
    "\n",
    "You need to write Spark code to perform the steps mentioned below. You\n",
    "should write it to optimize for execution speed.\n",
    "\n",
    "#### Filter the complete dataset for DISH = (Biryani or Pizza or Dosa) from X, where X is the complete dataset\n",
    "#### Group by ORDERID, STOREID, PRICE\n",
    "#### If the number of records in the group are > 1\n",
    "##### If the group just has records with DISH = Biryani\n",
    "##### Just keep one record with the following updated:\n",
    "TOTALAMOUNT = SUM(TOTALAMOUNT)\n",
    "QUANTITY = SUM(QUANTITY)\n",
    "JUSTANOTHERFEATURE = SUM(JUSTANOTHERFEATURE)\n",
    "#### 2. If the group consists of records with DISH = Biryani and DISH = Pizza or Dosa\n",
    "Compute SUM(TOTALAMOUNT)\n",
    "If SUM(TOTALAMOUNT) ≤ 0, drop all these records\n",
    "If SUM(TOTALAMOUNT) > 0,\n",
    "Find and keep one record with a positive TOTALAMOUNT and DISH = Pizza\n",
    "or Dosa and update the following:\n",
    "\n",
    "TOTALAMOUNT = SUM(TOTALAMOUNT)\n",
    "QUANTITY = SUM(QUANTITY)\n",
    "JUSTANOTHERFEATURE = SUM(JUSTANOTHERFEATURE)\n",
    "If SUM(QUANTITY)=0:\n",
    "If TOTALAMOUNT > 0:\n",
    "QUANTITY = 10\n",
    "JUSTANOTHERFEATURE = 20\n",
    "If TOTALAMOUNT < 0:\n",
    "QUANTITY = -20\n",
    "JUSTANOTHERFEATURE = -10\n",
    "\n",
    "In case you can't find such a record, drop all these records\n",
    "\n",
    "3. Update the column JUSTANOTHERFEATURE with a list of distinct values\n",
    "which are greater than 1 in that column for the group.\n",
    "\n",
    " Else do nothing.\n",
    " Merge it back with X and write to the output to a S3 path partitioned by the\n",
    "DISH name.\n",
    "\n",
    "In case you assume anything about the problem statement while writing the\n",
    "code for it, please do mention it.\n",
    "\n",
    "\n",
    "### We can get Dataset from the given link\n",
    "https://drive.google.com/file/d/1JbO0JS9UKZdqhwLrTRVYfivTLycfOrpC/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9fc6cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rita/Documents/Spark/Assignments\r\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env bash\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40d8083e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import explode, split, window,substring, col\n",
    "from pyspark.sql.functions import *\n",
    "from datetime import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47721dfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ca6dbc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/25 15:44:47 WARN Utils: Your hostname, EMPID21092 resolves to a loopback address: 127.0.1.1; using 192.168.1.6 instead (on interface wlp3s0)\n",
      "22/01/25 15:44:47 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/01/25 15:44:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/01/25 15:44:49 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"Window Function Assignment\").master(\"local[*]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ac7d277",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 0:>                                                          (0 + 1) / 1]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.format(\"parquet\").options(header='true', inferschema='true', delimiter=',').load(\"/home/rita/Documents/Spark/Assignments/spark_assignment_data.snappy.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9190bc51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+-------+-----------------+------------------+--------+------------------+\n",
      "| DISH| ORDERID|STOREID|            PRICE|       TOTALAMOUNT|QUANTITY|JUSTANOTHERFEATURE|\n",
      "+-----+--------+-------+-----------------+------------------+--------+------------------+\n",
      "|Pizza|ggeabhic|  fihdf|            44.39|23.532000000000004|     2.0|               2.0|\n",
      "|Pizza|ccfcbhid|  fihdf|            44.39|11.766000000000002|     1.0|               1.0|\n",
      "|Pizza| diebhid|  hbaeh|67.49000000000001|            39.812|     2.0|               2.0|\n",
      "|Pizza|gdigbhid|  fihdf|            44.39|11.766000000000002|     1.0|               1.0|\n",
      "|Pizza|cefdbhid|  eihde|            44.39|11.766000000000002|     1.0|               1.0|\n",
      "|Pizza|bdcjbhid|  hfaeh|            44.39|            35.298|     3.0|               3.0|\n",
      "|Pizza|hgbfbhid|  fihdf|            44.39|23.532000000000004|     2.0|               2.0|\n",
      "|Pizza|edjebhid|  fihdf|            44.39|23.532000000000004|     2.0|               2.0|\n",
      "|Pizza| deebhid|  hbaeh|67.49000000000001|            19.906|     1.0|               1.0|\n",
      "|Pizza| bfjbhid|  dihdd|            44.39|11.766000000000002|     1.0|               1.0|\n",
      "|Pizza|hcchbhid|  hfaeh|            44.39|11.766000000000002|     1.0|               1.0|\n",
      "|Pizza|fbbdbhid|  hbaeh|67.49000000000001|            39.812|     2.0|               2.0|\n",
      "|Pizza|bbdbbhid|  idhdi|            73.79|            22.126|     1.0|               1.0|\n",
      "|Pizza| egabhid|  gihdg|            44.39|            35.298|     3.0|               3.0|\n",
      "|Pizza|heihbhid|  hfaeh|            44.39|11.766000000000002|     1.0|               1.0|\n",
      "|Pizza|hdhjbhid|  dihdd|            44.39| 47.06400000000001|     4.0|               4.0|\n",
      "|Pizza|ehjgbhid|  afaea|67.49000000000001|            19.906|     1.0|               1.0|\n",
      "|Pizza|dhiibhid|  gihdg|            44.39|11.766000000000002|     1.0|               1.0|\n",
      "|Pizza| ebebhie|  hfaeh|            44.39|11.766000000000002|     1.0|               1.0|\n",
      "|Pizza| bdbbhic|  hfaeh|            44.39|23.532000000000004|     2.0|               2.0|\n",
      "+-----+--------+-------+-----------------+------------------+--------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e7a9d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1129292, 7)\n"
     ]
    }
   ],
   "source": [
    "print((df.count(), len(df.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4022670",
   "metadata": {},
   "source": [
    "### Filter the complete dataset for DISH = (Biryani or Pizza or Dosa) from X, where X is the complete dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36f01280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------+-------+-----------------+------------------+--------+------------------+\n",
      "| DISH| ORDERID|STOREID|            PRICE|       TOTALAMOUNT|QUANTITY|JUSTANOTHERFEATURE|\n",
      "+-----+--------+-------+-----------------+------------------+--------+------------------+\n",
      "|Pizza|ggeabhic|  fihdf|            44.39|23.532000000000004|     2.0|               2.0|\n",
      "|Pizza|ccfcbhid|  fihdf|            44.39|11.766000000000002|     1.0|               1.0|\n",
      "|Pizza| diebhid|  hbaeh|67.49000000000001|            39.812|     2.0|               2.0|\n",
      "|Pizza|gdigbhid|  fihdf|            44.39|11.766000000000002|     1.0|               1.0|\n",
      "|Pizza|cefdbhid|  eihde|            44.39|11.766000000000002|     1.0|               1.0|\n",
      "|Pizza|bdcjbhid|  hfaeh|            44.39|            35.298|     3.0|               3.0|\n",
      "|Pizza|hgbfbhid|  fihdf|            44.39|23.532000000000004|     2.0|               2.0|\n",
      "|Pizza|edjebhid|  fihdf|            44.39|23.532000000000004|     2.0|               2.0|\n",
      "|Pizza| deebhid|  hbaeh|67.49000000000001|            19.906|     1.0|               1.0|\n",
      "|Pizza| bfjbhid|  dihdd|            44.39|11.766000000000002|     1.0|               1.0|\n",
      "|Pizza|hcchbhid|  hfaeh|            44.39|11.766000000000002|     1.0|               1.0|\n",
      "|Pizza|fbbdbhid|  hbaeh|67.49000000000001|            39.812|     2.0|               2.0|\n",
      "|Pizza|bbdbbhid|  idhdi|            73.79|            22.126|     1.0|               1.0|\n",
      "|Pizza| egabhid|  gihdg|            44.39|            35.298|     3.0|               3.0|\n",
      "|Pizza|heihbhid|  hfaeh|            44.39|11.766000000000002|     1.0|               1.0|\n",
      "|Pizza|hdhjbhid|  dihdd|            44.39| 47.06400000000001|     4.0|               4.0|\n",
      "|Pizza|ehjgbhid|  afaea|67.49000000000001|            19.906|     1.0|               1.0|\n",
      "|Pizza|dhiibhid|  gihdg|            44.39|11.766000000000002|     1.0|               1.0|\n",
      "|Pizza| ebebhie|  hfaeh|            44.39|11.766000000000002|     1.0|               1.0|\n",
      "|Pizza| bdbbhic|  hfaeh|            44.39|23.532000000000004|     2.0|               2.0|\n",
      "+-----+--------+-------+-----------------+------------------+--------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dishes = ['Biryani','Pizza','Dosa']\n",
    "filtered_df = df.filter(df.DISH.isin(dishes))\n",
    "filtered_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1132251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(805280, 7)\n"
     ]
    }
   ],
   "source": [
    "print((filtered_df.count(), len(filtered_df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1d229628",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 34:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---------+------------------+-------+\n",
      "| ORDERID|  STOREID|             PRICE|records|\n",
      "+--------+---------+------------------+-------+\n",
      "|dfebbhid|    dihdd|             44.39|      1|\n",
      "|eabhbhid|    bgaeb| 67.49000000000001|      1|\n",
      "| djebhid|    hfaeh|             44.39|      1|\n",
      "|dahibhid|    achha|            140.99|      1|\n",
      "|jjijbhid|    gbigg|             69.59|      1|\n",
      "|cghebhid|   abiaha|            130.49|      1|\n",
      "|cbhebhid|   afijia|262.78999999999996|      1|\n",
      "|gjjhbhid|   ccjcbc|             31.79|      1|\n",
      "|icijbhid|   bgadjb|             56.99|      1|\n",
      "|jddbbhid|   fjddif|             52.79|      1|\n",
      "| bfebhid|   bgadjb|             56.99|      1|\n",
      "|iacebhid|   dcejjd|             56.99|      1|\n",
      "|dgaibhid|jcjiihcbj|             46.49|      1|\n",
      "|fgcebhid|fgdbgdiff|            199.79|      1|\n",
      "|  dgbhid|abgjhfcba|             73.79|      1|\n",
      "|cdgabhid|fgcdfbcbf|             52.79|      1|\n",
      "|ghgjbhid|abffgiifa|             42.29|      1|\n",
      "|ibjbbhid|   eeegce|             94.79|      1|\n",
      "|fchfbhic|   aeegca|             94.79|      1|\n",
      "|biccbhid|   hdegch|             94.79|      1|\n",
      "+--------+---------+------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "grouped_filtered_data = filtered_df.select('*').groupby(col('ORDERID'),col('STOREID'),col('PRICE')).agg(count('*').alias(\"records\"))\n",
    "grouped_filtered_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "087ffa5a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'total_amount'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_51060/1806637625.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrouped_filtered_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"count\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrouped_filtered_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecords\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrouped_filtered_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtotal_amount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1657\u001b[0m         \"\"\"\n\u001b[1;32m   1658\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1659\u001b[0;31m             raise AttributeError(\n\u001b[0m\u001b[1;32m   1660\u001b[0m                 \"'%s' object has no attribute '%s'\" % (self.__class__.__name__, name))\n\u001b[1;32m   1661\u001b[0m         \u001b[0mjc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'total_amount'"
     ]
    }
   ],
   "source": [
    "df_1 = grouped_filtered_data.withColumn(\"count\", when(grouped_filtered_data.records > 1, sum(grouped_filtered_data.total_amount)))\n",
    "df_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3268c153",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
